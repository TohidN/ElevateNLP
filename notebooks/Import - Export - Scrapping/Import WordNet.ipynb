{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f8a9e2",
   "metadata": {},
   "source": [
    "# WordNet dataset\n",
    "Import WordNet (Miller, 1990; Fellbaum, 1998) lexical database of semantic relations using nltk framework.\n",
    "* [WordNet](https://wordnet.princeton.edu/)\n",
    "* [WordNet Documentation](https://wordnet.princeton.edu/documentation/)\n",
    "* [NLTK WordNet](https://www.nltk.org/howto/wordnet.html)\n",
    "* [Open Multilingual Wordnet(OMW)](http://compling.hss.ntu.edu.sg/omw/)\n",
    "\n",
    "Other alternatives to WordNet available in NLTK:\n",
    "* wordnet2021: Open English Wordnet 2021\n",
    "* wordnet31: Wordnet 3.1\n",
    "* wordnet: WordNet\n",
    "* extended_omw: Extended Open Multilingual WordNet\n",
    "* omw-1.4: Open Multilingual Wordnet\n",
    "* omw: Open Multilingual Wordnet\n",
    "\n",
    "To see latest available NLTK data use:\n",
    "\n",
    "`import nltk\n",
    "nltk.download()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff4b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "from datacore.models import DomainOntology, Concept, Definition, Example, Relation, Language, Word, Component, WordCollection, WordRelation, WordRelationType, Reference, DataSource\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3377f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "english, created = Language.objects.get_or_create(en_name='English', native_name='English', alpha2='en')\n",
    "antonym, created = WordRelationType.objects.get_or_create(title='Antonym', descriptor='is opposite of', reverse_descriptor=\"is opposite of\", direction_type='u')\n",
    "pertainym, created = WordRelationType.objects.get_or_create(title='Pertainym', descriptor='is pertaining to', reverse_descriptor=\"is pertaining to\", direction_type='u')\n",
    "derivationally_related_forms, created = WordRelationType.objects.get_or_create(title='Derivationally Related Form', descriptor='is derivationally related to', reverse_descriptor=\"is derivationally related to\", direction_type='u')\n",
    "\n",
    "Reference1, created  = Reference.objects.get_or_create(title=\"WordNet - official homepage\", url=\"shttps://wordnet.princeton.edu/\", description=\"\")\n",
    "Reference2, created  = Reference.objects.get_or_create(title=\"NLTK WordNet\", url=\"https://www.nltk.org/howto/wordnet.html\", description=\"\")\n",
    "data_source, created = DataSource.objects.get_or_create(title=\"WordNet\", version=wn.get_version())\n",
    "data_source.references.add(Reference1, Reference2)\n",
    "\n",
    "ontology, created = DomainOntology.objects.get_or_create(title=\"WordNet Upper Ontology\")\n",
    "\n",
    "synset_count = 0\n",
    "for synset in wn.all_synsets(): synset_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f27a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Deleting all objects from database.\n",
    "Relation.objects.all().delete()\n",
    "Definition.objects.all().delete()\n",
    "Example.objects.all().delete()\n",
    "Concept.objects.all().delete()\n",
    "\n",
    "# Reset ID of models to start from 0\n",
    "from django.db import connection\n",
    "from django.core.management.color import no_style\n",
    "sequence_sql = connection.ops.sequence_reset_sql(no_style(), [Concept, Definition, Example, Relation])\n",
    "with connection.cursor() as cursor:\n",
    "    for sql in sequence_sql:\n",
    "        cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4102c11",
   "metadata": {},
   "source": [
    "### Importing concepts\n",
    "Wordnet under nltk should not require error handling. however older version could throw exceptions due to bug in it's io process. so I kept it just incase some older versions of WordNet were used.\n",
    "\n",
    "We can itterate over wordnet synsets with `wn.all_synsets()`.\n",
    "or all Open Multilingual Wordnet we can use `wn.all_omw_synsets(lang=\"eng\")`.\n",
    "both libraries accept `lang` as a parameter to reteive synsets of a specific language and list of available languages can be found in their documentation.\n",
    "\n",
    "### Lemma Methods\n",
    "Each lemma is an synonym for the concept(synset). also each lemma has following relationships:\n",
    "* `antonyms()`: is opposite of ...\n",
    "* `derivationally_related_forms()`: is derivationally related to ...\n",
    "* `pertainyms()`: is pertaining to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbadc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b66fbc6f31e4f33a4e9642caec1fc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing wordnet concepts, lemmas(Synonyms and Antonyms), definitions and examples.\n",
    "for synset in tqdm(wn.all_synsets(), total=synset_count):\n",
    "    concept = Concept(pos=Component.get_by_wn(synset.pos()).code, source_offset=synset.offset(), ontology_domain=ontology)\n",
    "    concept.save()\n",
    "    concept.data_sources.add(data_source)\n",
    "    # add definition\n",
    "    definition, created = Definition.objects.get_or_create(text=synset.definition(), language=english)\n",
    "    definition.data_sources.add(data_source)\n",
    "    concept.definitions.add(definition)\n",
    "    # add examples\n",
    "    if synset.examples():\n",
    "        for ex in synset.examples():\n",
    "            example, created = Example.objects.get_or_create(text=ex, language=english)\n",
    "            example.data_sources.add(data_source)\n",
    "            concept.examples.add(example)\n",
    "            if synset.lemmas():\n",
    "                for lemma in synset.lemmas():\n",
    "                    if lemma.name() in ex or lemmatizer.lemmatize(lemma.name())in ex:\n",
    "                        lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                        obj_word, create = Word.objects.get_or_create(text=lemma_name, language=english)\n",
    "                        example.word = obj_word\n",
    "                        example.save()\n",
    "    # add lemmas(synonyms) and lexical relations(antonyms(), derivationally_related_forms(), and pertainyms())\n",
    "    if synset.lemmas():\n",
    "        for lemma in synset.lemmas():\n",
    "            lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "            # store multi-words in a single collection, while creating Word objects from it's components\n",
    "            words = re.split(r'\\s+|-|/', lemma_name.lower())\n",
    "            word_list = []\n",
    "            for word in words:\n",
    "                new_word, created = Word.objects.get_or_create(text=word, language=english)\n",
    "                word_list.append(new_word.id)\n",
    "            if len(words) > 1:\n",
    "                word_collection = WordCollection(words=word_list, collection_type=\"SEMANTIC-NGRAM\")\n",
    "            # Add Synonyms\n",
    "            lemma_obj, created = Word.objects.get_or_create(text=lemma_name, language=english)\n",
    "            concept.synonyms.add(lemma_obj)\n",
    "            # Add Antonyms\n",
    "            if lemma.antonyms():\n",
    "                for lemma in lemma.antonyms():\n",
    "                    # prepare and import antonym's lemma to database\n",
    "                    antonym_lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    antonym_obj, created = Word.objects.get_or_create(text=antonym_lemma_name, language=english)\n",
    "                    concept.antonyms.add(antonym_obj)\n",
    "                    # create word relation for antonym\n",
    "                    if WordRelation.objects.filter(words__contains=[lemma_obj.id, antonym_obj.id], word_relation=antonym).exists()==False:\n",
    "                        word_rel = WordRelation(words=[lemma_obj.id, antonym_obj.id], word_relation=antonym)\n",
    "                        word_rel.save()\n",
    "            # add pertainyms\n",
    "            if lemma.pertainyms():\n",
    "                for lemma in lemma.pertainyms():\n",
    "                    # prepare and import antonym's lemma to database\n",
    "                    pertainym_lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    pertainym_obj, created = Word.objects.get_or_create(text=pertainym_lemma_name, language=english)\n",
    "                    # create word relation for antonym\n",
    "                    if WordRelation.objects.filter(words__contains=[lemma_obj.id, pertainym_obj.id], word_relation=pertainym).exists()==False:\n",
    "                        word_rel = WordRelation(words=[lemma_obj.id, pertainym_obj.id], word_relation=pertainym)\n",
    "                        word_rel.save()\n",
    "            # Add derivationally_related_forms\n",
    "            if lemma.derivationally_related_forms():\n",
    "                for lemma in lemma.derivationally_related_forms():\n",
    "                    # prepare and import derivitive's lemma to database\n",
    "                    derivitive_lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    derivitive_obj, created = Word.objects.get_or_create(text=derivitive_lemma_name, language=english)\n",
    "                    # create word relation for antonym\n",
    "                    if WordRelation.objects.filter(words__contains=[lemma_obj.id, derivitive_obj.id], word_relation=derivationally_related_forms).exists()==False:\n",
    "                        word_rel = WordRelation(words=[lemma_obj.id, derivitive_obj.id], word_relation=derivationally_related_forms)\n",
    "                        word_rel.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f394c",
   "metadata": {},
   "source": [
    "### Importing Relationships\n",
    "`Relation.relation_type` property can be assigned from `RELATION` variable available in `datacore.components`.\n",
    "\n",
    "\n",
    "Synset methods:\n",
    "* hypernyms, instance_hypernyms\n",
    "* hyponyms, instance_hyponyms\n",
    "* member_holonyms, substance_holonyms, part_holonyms\n",
    "* member_meronyms, substance_meronyms, part_meronyms\n",
    "* attributes\n",
    "* entailments\n",
    "* causes\n",
    "* also_sees\n",
    "* verb_groups\n",
    "* similar_tos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a505e3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdba647f5d004ba987a90284fc0fdd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing concept relationships\n",
    "from datacore.components import RELATION\n",
    "\n",
    "def add_relation(synset, relations, code, ontology):\n",
    "    if relations:\n",
    "        for rel in relations:\n",
    "            target = Concept.objects.get(data_sources__id=data_source.id, source_offset=rel.offset(), pos=Component.get_by_wn(rel.pos()).code)\n",
    "            Relation.objects.create(concepts=[target.pk, syn_obj.pk], relation_type=code, ontology_domain=ontology)\n",
    "\n",
    "for synset in tqdm(wn.all_synsets(), total=synset_count):\n",
    "    # Get Synset from 'Concept' model\n",
    "    syn_obj = Concept.objects.get(data_sources__id=data_source.id, source_offset=synset.offset(), pos=Component.get_by_wn(synset.pos()).code)\n",
    "    \"\"\"\n",
    "    hypernyms and hyponyms, indicate being a kind of something else, or being an instance of something else\n",
    "    - hypernyms, instance_hypernyms\n",
    "    - hyponyms, instance_hyponyms\n",
    "    \"\"\"\n",
    "    # Hyponym: (hyponyms) is a kind of (synset)\n",
    "    # Hypernym: (Hypernym) is a supertype of (synset)\n",
    "    add_relation(synset=syn_obj, relations=synset.hyponyms(), code=\"HYPONYM\", ontology=ontology)\n",
    "    # instance_hyponyms: (instance_hyponyms) is an instance of (synset)\n",
    "    # instance_hypernyms: (instance_hyponyms) has the instance (synset)\n",
    "    add_relation(synset=syn_obj, relations=synset.instance_hyponyms(), code=\"INSTANCE_OF\", ontology=ontology)\n",
    "\n",
    "    \"\"\"\n",
    "    holonyms and meronyms, indicating membership in group, having substance(s), and having part(s)\n",
    "    * member_holonyms, substance_holonyms, part_holonyms\n",
    "    * member_meronyms, substance_meronyms, part_meronyms\n",
    "    \"\"\"\n",
    "    # member_meronyms: (synset) has member (member_meronyms)\n",
    "    # member_holonyms: (synset) is a member of (member_holonyms)\n",
    "    add_relation(synset=syn_obj, relations=synset.member_meronyms(), code=\"MEMBER_HOLONYM\", ontology=ontology)\n",
    "    # part_meronyms: (synset) has part (part_meronyms)\n",
    "    # part_holonyms: (synset) is part of (part_holonyms)\n",
    "    add_relation(synset=syn_obj, relations=synset.part_meronyms(), code=\"PART_HOLONYM\", ontology=ontology)\n",
    "    # substance_meronyms: (synset) has substance (substance_meronyms)\n",
    "    # substance_holonyms (synset) is substance of (substance_holonyms)\n",
    "    add_relation(synset=syn_obj, relations=synset.substance_meronyms(), code=\"SUBSTANCE_HOLONYM\", ontology=ontology)\n",
    "    \"\"\"\n",
    "    domain: topic domains, region domains, and usage domains\n",
    "    topic_domains, region_domains, usage_domains\n",
    "    in_topic_domains, in_region_domains, in_usage_domains \n",
    "    \"\"\"\n",
    "    # topic_domains: (topic_domains) is under topic domain of (synset)\n",
    "    # in_topic_domains: (in_topic_domains) is in topic domain of (synset)\n",
    "    add_relation(synset=syn_obj, relations=synset.in_topic_domains(), code=\"TOPIC_DOMAINS\", ontology=ontology)\n",
    "    # region_domains: (region_domains) is relatet to region (synset)\n",
    "    # in_region_domains: (in_region_domains) region is related to (synset)\n",
    "    add_relation(synset=syn_obj, relations=synset.in_region_domains(), code=\"REGION_DOMAINS\", ontology=ontology)\n",
    "    # usage_domains: (usage_domains) linguistically is a (synset)\n",
    "    # in_usage_domains: (in_usage_domains) as an example has (synset)\n",
    "    add_relation(synset=syn_obj, relations=synset.in_usage_domains(), code=\"USAGE_DOMAINS\", ontology=ontology)\n",
    "\n",
    "    # attributes: (synset - Adjective) has the attribute (attributes)\n",
    "    if synset.pos()=='a':\n",
    "        add_relation(synset=syn_obj, relations=synset.attributes(), code=\"ATTRIBUTES\", ontology=ontology)\n",
    "    # entailments: (synset) entailments (entailments)\n",
    "    add_relation(synset=syn_obj, relations=synset.entailments(), code=\"ENTAILMENTS\", ontology=ontology)\n",
    "    # causes: (synset) causes (causes)\n",
    "    add_relation(synset=syn_obj, relations=synset.causes(), code=\"CAUSES\", ontology=ontology)\n",
    "    # also_sees: (synset) is related to (also_sees)\n",
    "    add_relation(synset=syn_obj, relations=synset.also_sees(), code=\"ALSO_SEES\", ontology=ontology)\n",
    "    # also_sees: (synset) verb is grouped with (also_sees)\n",
    "    add_relation(synset=syn_obj, relations=synset.verb_groups(), code=\"VERB_GROUP\", ontology=ontology)\n",
    "    # also_sees: (synset) is similar to (also_sees)\n",
    "    add_relation(synset=synset, relations=synset.similar_tos(), code=\"SIMILAR_TOS\", ontology=ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d601387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
