{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f8a9e2",
   "metadata": {},
   "source": [
    "# WordNet dataset\n",
    "Import WordNet (Miller, 1990; Fellbaum, 1998) lexical database of semantic relations using nltk framework.\n",
    "* [WordNet](https://wordnet.princeton.edu/)\n",
    "* [WordNet Documentation](https://wordnet.princeton.edu/documentation/)\n",
    "* [NLTK WordNet](https://www.nltk.org/howto/wordnet.html)\n",
    "* [Open Multilingual Wordnet(OMW)](http://compling.hss.ntu.edu.sg/omw/)\n",
    "\n",
    "Other alternatives to WordNet available in NLTK:\n",
    "* wordnet2021: Open English Wordnet 2021\n",
    "* wordnet31: Wordnet 3.1\n",
    "* wordnet: WordNet\n",
    "* extended_omw: Extended Open Multilingual WordNet\n",
    "* omw-1.4: Open Multilingual Wordnet\n",
    "* omw: Open Multilingual Wordnet\n",
    "\n",
    "To see latest available NLTK data use:\n",
    "\n",
    "`import nltk\n",
    "nltk.download()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff4b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "from datacore.models import (\n",
    "    DomainOntology,\n",
    "    Concept,\n",
    "    Definition,\n",
    "    Example,\n",
    "    Relation,\n",
    "    Language,\n",
    "    Word,\n",
    "    Component,\n",
    "    WordCollection,\n",
    "    WordRelation,\n",
    "    WordRelationType,\n",
    "    Reference,\n",
    "    DataSource,\n",
    ")\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3377f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "english, created = Language.objects.get_or_create(\n",
    "    en_name=\"English\", native_name=\"English\", alpha2=\"en\"\n",
    ")\n",
    "antonym, created = WordRelationType.objects.get_or_create(\n",
    "    title=\"Antonym\",\n",
    "    descriptor=\"is opposite of\",\n",
    "    reverse_descriptor=\"is opposite of\",\n",
    "    direction_type=\"u\",\n",
    ")\n",
    "pertainym, created = WordRelationType.objects.get_or_create(\n",
    "    title=\"Pertainym\",\n",
    "    descriptor=\"is pertaining to\",\n",
    "    reverse_descriptor=\"is pertaining to\",\n",
    "    direction_type=\"u\",\n",
    ")\n",
    "derivationally_related_forms, created = WordRelationType.objects.get_or_create(\n",
    "    title=\"Derivationally Related Form\",\n",
    "    descriptor=\"is derivationally related to\",\n",
    "    reverse_descriptor=\"is derivationally related to\",\n",
    "    direction_type=\"u\",\n",
    ")\n",
    "\n",
    "Reference1, created = Reference.objects.get_or_create(\n",
    "    title=\"WordNet - official homepage\",\n",
    "    url=\"shttps://wordnet.princeton.edu/\",\n",
    "    description=\"\",\n",
    ")\n",
    "Reference2, created = Reference.objects.get_or_create(\n",
    "    title=\"NLTK WordNet\", url=\"https://www.nltk.org/howto/wordnet.html\", description=\"\"\n",
    ")\n",
    "data_source, created = DataSource.objects.get_or_create(\n",
    "    title=\"WordNet\", version=wn.get_version()\n",
    ")\n",
    "data_source.references.add(Reference1, Reference2)\n",
    "\n",
    "ontology, created = DomainOntology.objects.get_or_create(title=\"WordNet Upper Ontology\")\n",
    "\n",
    "synset_count = 0\n",
    "for synset in wn.all_synsets():\n",
    "    synset_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f27a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Deleting all objects from database.\n",
    "Relation.objects.all().delete()\n",
    "Definition.objects.all().delete()\n",
    "Example.objects.all().delete()\n",
    "Concept.objects.all().delete()\n",
    "\n",
    "# Reset ID of models to start from 0\n",
    "from django.db import connection\n",
    "from django.core.management.color import no_style\n",
    "\n",
    "sequence_sql = connection.ops.sequence_reset_sql(\n",
    "    no_style(), [Concept, Definition, Example, Relation]\n",
    ")\n",
    "with connection.cursor() as cursor:\n",
    "    for sql in sequence_sql:\n",
    "        cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4102c11",
   "metadata": {},
   "source": [
    "### Importing concepts\n",
    "Wordnet under nltk should not require error handling. however older version could throw exceptions due to bug in it's io process. so I kept it just incase some older versions of WordNet were used.\n",
    "\n",
    "We can itterate over wordnet synsets with `wn.all_synsets()`.\n",
    "or all Open Multilingual Wordnet we can use `wn.all_omw_synsets(lang=\"eng\")`.\n",
    "both libraries accept `lang` as a parameter to reteive synsets of a specific language and list of available languages can be found in their documentation.\n",
    "\n",
    "### Lemma Methods\n",
    "Each lemma is an synonym for the concept(synset). also each lemma has following relationships:\n",
    "* `antonyms()`: is opposite of ...\n",
    "* `derivationally_related_forms()`: is derivationally related to ...\n",
    "* `pertainyms()`: is pertaining to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbadc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b66fbc6f31e4f33a4e9642caec1fc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing wordnet concepts, lemmas(Synonyms and Antonyms), definitions and examples.\n",
    "for synset in tqdm(wn.all_synsets(), total=synset_count):\n",
    "    concept = Concept(\n",
    "        pos=Component.get_by_wn(synset.pos()).code,\n",
    "        source_offset=synset.offset(),\n",
    "        ontology_domain=ontology,\n",
    "    )\n",
    "    concept.save()\n",
    "    concept.data_sources.add(data_source)\n",
    "    # add definition\n",
    "    definition, created = Definition.objects.get_or_create(\n",
    "        text=synset.definition(), language=english\n",
    "    )\n",
    "    definition.data_sources.add(data_source)\n",
    "    concept.definitions.add(definition)\n",
    "    # add examples\n",
    "    if synset.examples():\n",
    "        for ex in synset.examples():\n",
    "            example, created = Example.objects.get_or_create(text=ex, language=english)\n",
    "            example.data_sources.add(data_source)\n",
    "            concept.examples.add(example)\n",
    "            if synset.lemmas():\n",
    "                for lemma in synset.lemmas():\n",
    "                    if lemma.name() in ex or lemmatizer.lemmatize(lemma.name()) in ex:\n",
    "                        lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                        obj_word, create = Word.objects.get_or_create(\n",
    "                            text=lemma_name, language=english\n",
    "                        )\n",
    "                        example.word = obj_word\n",
    "                        example.save()\n",
    "    # add lemmas(synonyms) and lexical relations(antonyms(), derivationally_related_forms(), and pertainyms())\n",
    "    if synset.lemmas():\n",
    "        for lemma in synset.lemmas():\n",
    "            lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "            # store multi-words in a single collection, while creating Word objects from it's components\n",
    "            words = re.split(r\"\\s+|-|/\", lemma_name.lower())\n",
    "            word_list = []\n",
    "            for word in words:\n",
    "                new_word, created = Word.objects.get_or_create(\n",
    "                    text=word, language=english\n",
    "                )\n",
    "                word_list.append(new_word.id)\n",
    "            if len(words) > 1:\n",
    "                word_collection = WordCollection(\n",
    "                    words=word_list, collection_type=\"SEMANTIC-NGRAM\"\n",
    "                )\n",
    "            # Add Synonyms\n",
    "            lemma_obj, created = Word.objects.get_or_create(\n",
    "                text=lemma_name, language=english\n",
    "            )\n",
    "            concept.synonyms.add(lemma_obj)\n",
    "            # Add Antonyms\n",
    "            if lemma.antonyms():\n",
    "                for lemma in lemma.antonyms():\n",
    "                    # prepare and import antonym's lemma to database\n",
    "                    antonym_lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    antonym_obj, created = Word.objects.get_or_create(\n",
    "                        text=antonym_lemma_name, language=english\n",
    "                    )\n",
    "                    concept.antonyms.add(antonym_obj)\n",
    "                    # create word relation for antonym\n",
    "                    if (\n",
    "                        WordRelation.objects.filter(\n",
    "                            words__contains=[lemma_obj.id, antonym_obj.id],\n",
    "                            word_relation=antonym,\n",
    "                        ).exists()\n",
    "                        == False\n",
    "                    ):\n",
    "                        word_rel = WordRelation(\n",
    "                            words=[lemma_obj.id, antonym_obj.id], word_relation=antonym\n",
    "                        )\n",
    "                        word_rel.save()\n",
    "            # add pertainyms\n",
    "            if lemma.pertainyms():\n",
    "                for lemma in lemma.pertainyms():\n",
    "                    # prepare and import antonym's lemma to database\n",
    "                    pertainym_lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    pertainym_obj, created = Word.objects.get_or_create(\n",
    "                        text=pertainym_lemma_name, language=english\n",
    "                    )\n",
    "                    # create word relation for antonym\n",
    "                    if (\n",
    "                        WordRelation.objects.filter(\n",
    "                            words__contains=[lemma_obj.id, pertainym_obj.id],\n",
    "                            word_relation=pertainym,\n",
    "                        ).exists()\n",
    "                        == False\n",
    "                    ):\n",
    "                        word_rel = WordRelation(\n",
    "                            words=[lemma_obj.id, pertainym_obj.id],\n",
    "                            word_relation=pertainym,\n",
    "                        )\n",
    "                        word_rel.save()\n",
    "            # Add derivationally_related_forms\n",
    "            if lemma.derivationally_related_forms():\n",
    "                for lemma in lemma.derivationally_related_forms():\n",
    "                    # prepare and import derivitive's lemma to database\n",
    "                    derivitive_lemma_name = lemma.name().replace(\"_\", \" \")\n",
    "                    derivitive_obj, created = Word.objects.get_or_create(\n",
    "                        text=derivitive_lemma_name, language=english\n",
    "                    )\n",
    "                    # create word relation for antonym\n",
    "                    if (\n",
    "                        WordRelation.objects.filter(\n",
    "                            words__contains=[lemma_obj.id, derivitive_obj.id],\n",
    "                            word_relation=derivationally_related_forms,\n",
    "                        ).exists()\n",
    "                        == False\n",
    "                    ):\n",
    "                        word_rel = WordRelation(\n",
    "                            words=[lemma_obj.id, derivitive_obj.id],\n",
    "                            word_relation=derivationally_related_forms,\n",
    "                        )\n",
    "                        word_rel.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f394c",
   "metadata": {},
   "source": [
    "### Importing Relationships\n",
    "`Relation.relation_type` property can be assigned from `RELATION` variable available in `datacore.components`.\n",
    "\n",
    "\n",
    "Synset methods:\n",
    "* hypernyms, instance_hypernyms\n",
    "* hyponyms, instance_hyponyms\n",
    "* member_holonyms, substance_holonyms, part_holonyms\n",
    "* member_meronyms, substance_meronyms, part_meronyms\n",
    "* attributes\n",
    "* entailments\n",
    "* causes\n",
    "* also_sees\n",
    "* verb_groups\n",
    "* similar_tos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a505e3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdba647f5d004ba987a90284fc0fdd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing concept relationships\n",
    "from datacore.components import RELATION\n",
    "\n",
    "\n",
    "def add_relation(synset, relations, code, ontology):\n",
    "    if relations:\n",
    "        for rel in relations:\n",
    "            target = Concept.objects.get(\n",
    "                data_sources__id=data_source.id,\n",
    "                source_offset=rel.offset(),\n",
    "                pos=Component.get_by_wn(rel.pos()).code,\n",
    "            )\n",
    "            Relation.objects.create(\n",
    "                concepts=[target.pk, syn_obj.pk],\n",
    "                relation_type=code,\n",
    "                ontology_domain=ontology,\n",
    "            )\n",
    "\n",
    "\n",
    "for synset in tqdm(wn.all_synsets(), total=synset_count):\n",
    "    # Get Synset from 'Concept' model\n",
    "    syn_obj = Concept.objects.get(\n",
    "        data_sources__id=data_source.id,\n",
    "        source_offset=synset.offset(),\n",
    "        pos=Component.get_by_wn(synset.pos()).code,\n",
    "    )\n",
    "    \"\"\"\n",
    "    hypernyms and hyponyms, indicate being a kind of something else, or being an instance of something else\n",
    "    - hypernyms, instance_hypernyms\n",
    "    - hyponyms, instance_hyponyms\n",
    "    \"\"\"\n",
    "    # Hyponym: (hyponyms) is a kind of (synset)\n",
    "    # Hypernym: (Hypernym) is a supertype of (synset)\n",
    "    add_relation(\n",
    "        synset=syn_obj, relations=synset.hyponyms(), code=\"HYPONYM\", ontology=ontology\n",
    "    )\n",
    "    # instance_hyponyms: (instance_hyponyms) is an instance of (synset)\n",
    "    # instance_hypernyms: (instance_hyponyms) has the instance (synset)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.instance_hyponyms(),\n",
    "        code=\"INSTANCE_OF\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    holonyms and meronyms, indicating membership in group, having substance(s), and having part(s)\n",
    "    * member_holonyms, substance_holonyms, part_holonyms\n",
    "    * member_meronyms, substance_meronyms, part_meronyms\n",
    "    \"\"\"\n",
    "    # member_meronyms: (synset) has member (member_meronyms)\n",
    "    # member_holonyms: (synset) is a member of (member_holonyms)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.member_meronyms(),\n",
    "        code=\"MEMBER_HOLONYM\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # part_meronyms: (synset) has part (part_meronyms)\n",
    "    # part_holonyms: (synset) is part of (part_holonyms)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.part_meronyms(),\n",
    "        code=\"PART_HOLONYM\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # substance_meronyms: (synset) has substance (substance_meronyms)\n",
    "    # substance_holonyms (synset) is substance of (substance_holonyms)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.substance_meronyms(),\n",
    "        code=\"SUBSTANCE_HOLONYM\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    \"\"\"\n",
    "    domain: topic domains, region domains, and usage domains\n",
    "    topic_domains, region_domains, usage_domains\n",
    "    in_topic_domains, in_region_domains, in_usage_domains \n",
    "    \"\"\"\n",
    "    # topic_domains: (topic_domains) is under topic domain of (synset)\n",
    "    # in_topic_domains: (in_topic_domains) is in topic domain of (synset)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.in_topic_domains(),\n",
    "        code=\"TOPIC_DOMAINS\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # region_domains: (region_domains) is relatet to region (synset)\n",
    "    # in_region_domains: (in_region_domains) region is related to (synset)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.in_region_domains(),\n",
    "        code=\"REGION_DOMAINS\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # usage_domains: (usage_domains) linguistically is a (synset)\n",
    "    # in_usage_domains: (in_usage_domains) as an example has (synset)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.in_usage_domains(),\n",
    "        code=\"USAGE_DOMAINS\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "\n",
    "    # attributes: (synset - Adjective) has the attribute (attributes)\n",
    "    if synset.pos() == \"a\":\n",
    "        add_relation(\n",
    "            synset=syn_obj,\n",
    "            relations=synset.attributes(),\n",
    "            code=\"ATTRIBUTES\",\n",
    "            ontology=ontology,\n",
    "        )\n",
    "    # entailments: (synset) entailments (entailments)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.entailments(),\n",
    "        code=\"ENTAILMENTS\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # causes: (synset) causes (causes)\n",
    "    add_relation(\n",
    "        synset=syn_obj, relations=synset.causes(), code=\"CAUSES\", ontology=ontology\n",
    "    )\n",
    "    # also_sees: (synset) is related to (also_sees)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.also_sees(),\n",
    "        code=\"ALSO_SEES\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # also_sees: (synset) verb is grouped with (also_sees)\n",
    "    add_relation(\n",
    "        synset=syn_obj,\n",
    "        relations=synset.verb_groups(),\n",
    "        code=\"VERB_GROUP\",\n",
    "        ontology=ontology,\n",
    "    )\n",
    "    # also_sees: (synset) is similar to (also_sees)\n",
    "    add_relation(\n",
    "        synset=synset,\n",
    "        relations=synset.similar_tos(),\n",
    "        code=\"SIMILAR_TOS\",\n",
    "        ontology=ontology,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d601387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
