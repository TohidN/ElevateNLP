{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88d67454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "from nltk.corpus import wordnet as wn\n",
    "# for parsing\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab3ed23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01')\n",
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# get a single item\n",
    "print(wn.synset(\"dog.n.01\"))\n",
    "print(wn.synset(\"dog.n.01\").definition())\n",
    "print(wn.synset(\"dog.n.01\").attributes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59837d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> worse: ['better']\n",
      "> worse: ['better']\n",
      "> bad: ['good']\n",
      "> regretful: ['unregretful']\n"
     ]
    }
   ],
   "source": [
    "# antonyms for synsets with specific lemma\n",
    "for synset in wn.synsets(\"Worse\"):\n",
    "    for lemma in synset.lemmas():\n",
    "        lemma_name = lemma.name()\n",
    "        if lemma.antonyms():\n",
    "            antonym_names = [antonym.name() for antonym in lemma.antonyms()]\n",
    "            print(f\"> {lemma_name}: {antonym_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09552b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: worse, worse, worse, worsened, bad, bad, big, bad, tough, bad, spoiled, spoilt, regretful, sorry, bad, bad, uncollectible, bad, bad, bad, risky, high-risk, speculative, bad, unfit, unsound, bad, bad, bad, forged, bad, defective, worse\n",
      "Antonyms: better, better, good, unregretful\n"
     ]
    }
   ],
   "source": [
    "# Synonym and Antonims of synsets with specific lemma\n",
    "syn = list()\n",
    "ant = list()\n",
    "for synset in wn.synsets(\"Worse\"):\n",
    "    for lemma in synset.lemmas():\n",
    "        syn.append(lemma.name())    #add the synonyms\n",
    "        if lemma.antonyms():    #When antonyms are available, add them into the list\n",
    "            ant.append(lemma.antonyms()[0].name())\n",
    "print('Synonyms: ' + \", \".join(syn))\n",
    "print('Antonyms: ' + \", \".join(ant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8ea08da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definition: the sacred writings of the Christian religions\n",
      "attributes: []\n",
      "hypernyms: [Synset('sacred_text.n.01')]\n",
      "instance_hypernyms: []\n",
      "hyponyms: [Synset('family_bible.n.01')]\n",
      "instance_hyponyms: [Synset('american_standard_version.n.01'), Synset('authorized_version.n.01'), Synset('douay_bible.n.01'), Synset('new_english_bible.n.01'), Synset('revised_standard_version.n.01'), Synset('revised_version.n.01'), Synset('vulgate.n.01')]\n",
      "member_holonyms: []\n",
      "substance_holonyms: []\n",
      "part_holonyms: []\n",
      "member_meronyms: []\n",
      "substance_meronyms: []\n",
      "part_meronyms: [Synset('new_testament.n.01'), Synset('old_testament.n.01'), Synset('testament.n.04'), Synset('text.n.02')]\n",
      "topic_domains: []\n",
      "in_topic_domains: [Synset('covenant.n.02'), Synset('demythologize.v.01'), Synset('eisegesis.n.01'), Synset('exegesis.n.01'), Synset('gabriel.n.01'), Synset('noah's_flood.n.01')]\n",
      "region_domains: []\n",
      "in_region_domains: []\n",
      "usage_domains: []\n",
      "in_usage_domains: []\n",
      "entailments: []\n",
      "causes: []\n",
      "also_sees: []\n",
      "verb_groups: []\n",
      "similar_tos: []\n"
     ]
    }
   ],
   "source": [
    "# All synset methods\n",
    "synset = wn.synset(\"bible.n.01\")\n",
    "print(f\"definition: {synset.definition()}\")\n",
    "print(f\"attributes: {synset.attributes()}\")\n",
    "print(f\"hypernyms: {synset.hypernyms()}\")\n",
    "print(f\"instance_hypernyms: {synset.instance_hypernyms()}\")\n",
    "print(f\"hyponyms: {synset.hyponyms()}\")\n",
    "print(f\"instance_hyponyms: {synset.instance_hyponyms()}\")\n",
    "print(f\"member_holonyms: {synset.member_holonyms()}\")\n",
    "print(f\"substance_holonyms: {synset.substance_holonyms()}\")\n",
    "print(f\"part_holonyms: {synset.part_holonyms()}\")\n",
    "print(f\"member_meronyms: {synset.member_meronyms()}\")\n",
    "print(f\"substance_meronyms: {synset.substance_meronyms()}\")\n",
    "print(f\"part_meronyms: {synset.part_meronyms()}\")\n",
    "print(f\"topic_domains: {synset.topic_domains()}\")\n",
    "print(f\"in_topic_domains: {synset.in_topic_domains()}\")\n",
    "print(f\"region_domains: {synset.region_domains()}\")\n",
    "print(f\"in_region_domains: {synset.in_region_domains()}\")\n",
    "print(f\"usage_domains: {synset.usage_domains()}\")\n",
    "print(f\"in_usage_domains: {synset.in_usage_domains()}\")\n",
    "print(f\"entailments: {synset.entailments()}\")\n",
    "print(f\"causes: {synset.causes()}\")\n",
    "print(f\"also_sees: {synset.also_sees()}\")\n",
    "print(f\"verb_groups: {synset.verb_groups()}\")\n",
    "print(f\"similar_tos: {synset.similar_tos()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6fc0c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('human_genome_project.n.01')\n",
      "-Synset('scientific_research.n.01')\n",
      "--Synset('research.n.01')\n",
      "---Synset('investigation.n.02')\n",
      "----Synset('work.n.01')\n",
      "-----Synset('activity.n.01')\n",
      "------Synset('act.n.02')\n",
      "-------Synset('event.n.01')\n",
      "--------Synset('psychological_feature.n.01')\n",
      "---------Synset('abstraction.n.06')\n",
      "----------Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "# Hypernim Tree\n",
    "def get_hypernym(synset, counter):\n",
    "    tab = \"-\" * counter\n",
    "    print(f\"{tab}{synset}\")\n",
    "    if synset.hypernyms():\n",
    "        for hypernym in synset.hypernyms():\n",
    "            get_hypernym(hypernym, counter+1)\n",
    "    else:\n",
    "        for hypernym in synset.instance_hypernyms():\n",
    "            get_hypernym(hypernym, counter+1)\n",
    "            \n",
    "synset = wn.synset(\"human_genome_project.n.01\")\n",
    "get_hypernym(synset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f3beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
